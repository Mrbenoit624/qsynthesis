#!/usr/bin/env python3

import sys
import argparse
from random import choice

from orderedset import OrderedSet
from itertools import permutations, combinations
import random
from pathlib import Path
import logging
from typing import List
import click
import time

import qsynthesis
from qsynthesis.grammar import TritonGrammar, BvOp, BoolOp
from qsynthesis.lookuptable import LookupTable, HashType
from qsynthesis.lookuptabledb import LookupTableDB

logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')


def biased_input_generator(bitsize:int, var_num: int, input_number: int, bs: int, random_level: int = 2):
    n = max(var_num-3, random_level)
    minus_one = pow(2, bitsize)-1
    vals = [1, 0, minus_one] + [None] * n
    all_perms = list(permutations(vals, var_num))
    return list(map(lambda l: [random.getrandbits(bs) if x is None else x for x in l], random.sample(all_perms, k=input_number)))


def operator_generator(nb_operator: int):
    """ Generate infinite operators set (making sure all combinations  """
    ops = [BvOp.NOT, BvOp.AND, BvOp.OR, BvOp.XOR, BvOp.NEG, BvOp.ADD, BvOp.MUL, BvOp.SUB]#, BvOp.SDIV]
    # FIXME: Take random operators among all!
    while 1:
        l = list(combinations(ops, nb_operator))
        random.shuffle(l)
        yield from l


@click.group(context_settings={'help_option_names': ['-h', '--help']})
@click.version_option(version=qsynthesis.__version__, message='%(version)s')
def main():
    pass


@main.command(name="generate")
@click.argument('output_file', type=str)
@click.option('--resume', metavar="resume file", type=str, help='resume resume lookup table generation from given file')
@click.option('-bs', '--bitsize', metavar="bitsize", default=64, type=int, help="Bit size of expressions")
@click.option('--var-num', default=3, type=int, help="Number of variables")
@click.option('--input-num', default=5, type=int, help="Number of inputs")
@click.option('--random-level', type=int, default=2, help="Randomness level of inputs 0 means higlhly biased to use corner-case values (0,1,-1)")
@click.option('--max-depth', default=5, type=int, help="Maximum depth")
@click.option('--op-num', default=5, type=int, help="Operator number")
@click.option("-v", "--verbosity", default=0, count=True, help="increase output verbosity")
@click.option('-k', default=1, type=int, help="Number of tables to generate")
@click.option('--ops', type=str, default='', help='specifying operators to uses')
@click.option('--inputs', type=str, default='', help='specifying input vector to use')
@click.option('--hash-mode', default=HashType.RAW, type=click.Choice([x.name for x in HashType]), help="Hash function for keys in table")
@click.option('--watchdog', type=float, help="Activate RAM watchdog (percentage of load when to stop)")
@click.option('-t', '--type', type=click.Choice(["pkl", "db"]), default="db", help="Type of database to create")
@click.option('--linearization', is_flag=True, type=bool, default=False, help="If set activate linearization of expressions")
def generate_command(output_file, resume, bitsize, var_num, input_num, random_level, max_depth, op_num, verbosity, k, ops, inputs, hash_mode, watchdog, type, linearization):
    """ Table generation utility """

    logging.root.handlers = []
    logging.basicConfig(level=logging.INFO if verbosity else logging.WARNING, format='%(message)s')

    if resume is not None:
        pass  # TODO: implementing resume features
    else:
        out_dir = Path(output_file)
        if out_dir.exists() and out_dir.is_file():
            out_dir.unlink()
        if not out_dir.exists() and k > 1:
            out_dir.mkdir()

        ops = [BvOp[x] for x in ops.split(",")] if ops else None
        inputs = [int(x) for x in inputs.split(",") if x]

        t1 = time.time()

        for i in range(k):
            logging.info(f"Generate Table #{i}")
            p = out_dir/f"{i}.{type}" if k > 1 else out_dir

            operators = next(operator_generator(op_num)) if ops is None else ops
            vars = [chr(ord('a') + x) for x in range(var_num)]
            if inputs:
                inputs = [{n: v for n, v in zip(vars, inputs[i:i + len(vars)])} for i in
                          range(0, len(inputs), len(vars))]
            else:
                inputs = biased_input_generator(bitsize, var_num, input_num, bitsize, random_level)
                inputs = [{n: v for n, v in zip(vars, i)} for i in inputs]

            grammar = TritonGrammar([(x, bitsize) for x in vars], operators)

            logging.info(f"Watchdog value: {watchdog}")
            if type == "pkl":
                ltm = LookupTable(grammar, inputs, HashType[hash_mode], p.name)
            else:
                ltm = LookupTableDB.create(p.absolute(), grammar, inputs, HashType[hash_mode])
            try:
                if watchdog:
                    ltm.generate(depth=max_depth, do_watch=True, watchdog_threshold=watchdog, linearize=linearization)
                else:
                    ltm.generate(depth=max_depth, linearize=linearization)
            except KeyboardInterrupt:
                logging.warning("Stop required")

            if type == "pkl":
                ltm.dump(p)
        elapsed = time.time() - t1
        hours, rem = divmod(elapsed, 3600)
        minutes, seconds = divmod(rem, 60)
        logging.info(f"\n{int(hours)}h{int(minutes)}m{seconds:.2f}s")


@main.command(name="info")
@click.argument('table_file', type=click.Path(exists=True))
def infos_command(table_file):
    logging.root.handlers = []
    logging.basicConfig(level=logging.INFO, format='%(message)s')
    table_file = Path(table_file)

    if table_file.suffix == ".pkl":
        table = LookupTable.load(table_file)
    else:
        table = LookupTableDB.load(table_file)

    logging.info(f"Bitsize: {table.bitsize}")
    logging.info(f"Hash mode: {table.hash_mode.name}")
    logging.info(f"Size: {table.size}")
    logging.info(f"Variables: {table.grammar.vars}")
    logging.info(f"Operators: {[x.name for x in table.grammar.ops]}")
    logging.info(f"Nb inputs: {len(table.inputs)}")
    l = []
    for i in table.inputs:
        for v in i.values():
            l.append(v)
    logging.info(",".join(str(x) for x in l))


if __name__ == "__main__":
    main()
